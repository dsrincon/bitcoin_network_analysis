{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Bitcoin Transaction Network Analysis - Data Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of CPUs: 3\n"
     ]
    }
   ],
   "source": [
    "import blocksci\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import networkx as nx\n",
    "import matplotlib.pyplot as plt\n",
    "import multiprocessing as mp\n",
    "import itertools\n",
    "import gc\n",
    "from functools import partial\n",
    "%matplotlib notebook\n",
    "#ncpu=mp.cpu_count()\n",
    "ncpu=3\n",
    "print('Number of CPUs: {}'.format(ncpu))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "132"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total Blocks up to 2019-04-17 16:57:37:  572046 \n"
     ]
    }
   ],
   "source": [
    "# Point to parsed blockchain data\n",
    "chain = blocksci.Blockchain(\"/home/ubuntu/bitcoin\")\n",
    "total_blocks=chain.blocks\n",
    "print('Total Blocks up to {}:  {} '.format(total_blocks[-1].time,len(total_blocks)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Network Definition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define Block Range\n",
    "blocks=chain.range(start='2015-02-01 00:00:00',end='2017-02-01 11:59:59')\n",
    "types=blocksci.address_type.types\n",
    "txs=blocks.txes\n",
    "txs=[tx for tx in txs]\n",
    "\n",
    "print('Number of Blocks: {} '.format(len(blocks)))\n",
    "print('Highest block height: {}'.format(blocks[-1].height))\n",
    "print('Number of Transactions: {} '.format(len(txs)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of parts: 3\n",
      "556459 Processed\n",
      "556460 Processed\n",
      "556461 Processed\n"
     ]
    }
   ],
   "source": [
    "# Script that generates data for graphs in each part of the partition\n",
    "start='2019-02-01 00:00:00'\n",
    "end='2019-01-01 00:45:59'\n",
    "partition=BchainPartition(chain,start,end)\n",
    "df=partition_data(partition)\n",
    "df.head()\n",
    "\n",
    "# Save to csv\n",
    "# Define filename\n",
    "start_c=start\n",
    "start_c=start_c.replace('-','_').replace(' ','_').replace(':','_')\n",
    "end_c=end\n",
    "end_c=end_c.replace('-','_').replace(' ','_').replace(':','_')\n",
    "filename='blocks'+start_c+'-'+end_c+'.csv'\n",
    "# Save\n",
    "df.to_csv(filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Class that creates a blockchain a blockchain partition (dictionary) given data range and partition type (blocks,days,weeks)\n",
    "\n",
    "class BchainPartition():\n",
    "    \n",
    "    def __init__(self,chain,start_timestamp,end_timestamp,ptype='blocks'):\n",
    "        blocks=chain.range(start=start_timestamp,end=end_timestamp)\n",
    "        txs=blocks.txes\n",
    "        txs=[tx for tx in txs]\n",
    "        \n",
    "        if ptype=='blocks':\n",
    "            self.partition={b.height:[tx for tx in b.txes] for b in blocks}\n",
    "            self.no_parts=len(blocks)\n",
    "            \n",
    "        # ***TODO: Create partition for other types of partitions (use tx.block_time)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function that takes blockchain partition and outputs pandas data frame with features \n",
    "# for the graph defined by each split in the partition\n",
    "\n",
    "def partition_data(chainpartiton):\n",
    "    \n",
    "    # Dictionary with partition\n",
    "    partition=chainpartiton.partition\n",
    "    partindex=partition.keys()\n",
    "    parts=partition.values()\n",
    "    data_tuples=[]\n",
    "    \n",
    "    print('Number of parts: {}'.format(len(partindex)))\n",
    "    \n",
    "    tuples=[(index,part) for index,part in zip(partindex,parts)]\n",
    "    \n",
    "    \n",
    "    for t in tuples:\n",
    "        data_i,columns_i=graph_features(t)\n",
    "        data_tuples.append((data_i,columns_i))\n",
    "         \n",
    "    \n",
    "    '''    \n",
    "    chunksize=len(tuples)%ncpu\n",
    "    with mp.Pool(processes=ncpu) as pool:\n",
    "        data_tuples=pool.map(graph_features,tuples,chunksize)\n",
    "    \n",
    "    '''\n",
    "    \n",
    "    columns=data_tuples[0][1] #This value is being re-written. This design choice is to mantain consistency with columns.\n",
    "    data=[i for i,j in data_tuples]\n",
    "    data=np.array(data)    \n",
    "    df=pd.DataFrame(data=data[:,:],columns=columns)\n",
    "    \n",
    "    \n",
    "    return df\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function that receives a dictionary that receives a chain part (list of transactions), generates transaction graph and calculates statistics\n",
    "def graph_features(chain_part_tuple):\n",
    "    \n",
    "    index=chain_part_tuple[0]\n",
    "    chain_part=chain_part_tuple[1]\n",
    "    block_height=chain_part[-1].block_height\n",
    "    graph=block_graph(chain_part)\n",
    "    nodes=graph.nodes(data=True)\n",
    "    edges=graph.edges(data=True)\n",
    "    data=[index]  \n",
    "    columns=['block_height']\n",
    "    \n",
    "    # Number of Nodes\n",
    "    no_nodes=nx.number_of_nodes(graph)\n",
    "    data.append(no_nodes)\n",
    "    columns.append('no_nodes')\n",
    "    \n",
    "    # Number of Edges (address to address transactions)\n",
    "    no_edges=nx.number_of_edges(graph)\n",
    "    data.append(no_edges)\n",
    "    columns.append('no_edges')\n",
    "    \n",
    "    # Total value transacted\n",
    "    total_value=np.sum(np.array([a['value'] for n1,n2,a in edges]))\n",
    "    data.append(total_value)\n",
    "    columns.append('value_transacted')\n",
    "    \n",
    "    # Total Density\n",
    "    density=nx.density(graph)\n",
    "    data.append(density)\n",
    "    columns.append('total_density')\n",
    "    \n",
    "    # Nodes with self loops nx.loops nodes_with_selfloops(G) nodes_with_selfloops(G) \n",
    "    nodes_self=nx.number_of_selfloops(graph)\n",
    "    data.append(nodes_self)\n",
    "    columns.append('nodes_self')\n",
    "    \n",
    "    # Value of self loops nodes_with_selfloops(G)\n",
    "    values=np.array([a['value'] for n1,n2,a in nx.selfloop_edges(graph,data=True)])\n",
    "    selfloop_value=np.sum(values)\n",
    "    data.append(selfloop_value)\n",
    "    columns.append('selfloop_value')\n",
    "    \n",
    "    # Number of transactions to old addresses \n",
    "    \n",
    "    old_nodes=[n for n,a in nodes if a['block_created']<block_height]\n",
    "    edges_to_old=graph.in_edges(old_nodes,data=True)\n",
    "    data.append(len(edges_to_old))\n",
    "    columns.append('old_nodes_in')\n",
    "    \n",
    "    # Ratio of transactions to old addresses to total transactions\n",
    "    \n",
    "    ratio_oldin_totalin=len(edges_to_old)/no_edges\n",
    "    data.append(ratio_oldin_totalin)\n",
    "    columns.append('ratio_oldin_totalin')\n",
    "    \n",
    "    # Value of transactions to old addresses\n",
    "    \n",
    "    value_to_old=[a['value'] for n1,n2,a in edges_to_old]\n",
    "    data.append(np.sum(np.array(value_to_old)))\n",
    "    columns.append('value_to_old')\n",
    "    \n",
    "    # Old address density\n",
    "    \n",
    "    old_graph=nx.induced_subgraph(graph,old_nodes)\n",
    "    old_density=nx.density(old_graph)\n",
    "    data.append(old_density)\n",
    "    columns.append('old_density')\n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    # ***TODO*** (Aggregated graph analysis)\n",
    "    \n",
    "    # Accumulated reuse\n",
    "    # Dominance (Agg graph or new vs. old dominance) \n",
    "    #https://networkx.github.io/documentation/stable/reference/algorithms/dominance.html\n",
    "    # Common ancenstors (as with dominance the address ancestor path should be proportional \n",
    "    #to the blockchain lenght if address reuse is minimal)\n",
    "    #***********\n",
    "    \n",
    "    print('{} Processed'.format(index))\n",
    "    return (data,columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function that creates transaction graph for a given number of nodes\n",
    "\n",
    "\n",
    "def block_graph(txs):\n",
    "    \n",
    "    # Create graph and process \n",
    "    graph = nx.MultiDiGraph()\n",
    "    nodes=[]\n",
    "    edges=[]\n",
    "    \n",
    "    \n",
    "    # Extract transactions information\n",
    "    \n",
    "    init_block=txs[0].block.height\n",
    "    txs_dic={tx.index:tx for tx in txs}\n",
    "    txs_ix=list(txs_dic.keys())\n",
    "    txs_ix.sort()\n",
    "   \n",
    "    \n",
    "    start_ix=txs_ix[0]\n",
    "    end_ix=txs_ix[-1]\n",
    "    \n",
    "    \n",
    "    # Generate edges to input to graph\n",
    "    \n",
    "    chunksize=len(txs)%ncpu\n",
    "   \n",
    "    #edges=chain.mapreduce_txes(extract_nodes_edges, lambda x: x , init=None, start=start_ix, end=end_ix, cpu_count=8)\n",
    "    #edges=chain.mapreduce_txes(identity, identity, init=missing_param, start=start_ix, end=end_ix, cpu_count=8)\n",
    "\n",
    "    '''\n",
    "    with mp.Pool(processes=ncpu) as pool:\n",
    "        edges=pool.map(extract_nodes_edges,txs,chunksize)\n",
    "        \n",
    "   \n",
    "    '''\n",
    "    for tx in txs:\n",
    "        edges_i,nodes_i=extract_nodes_edges(tx)\n",
    "        nodes.append(nodes_i)\n",
    "        edges.append(edges_i)\n",
    "        #print('Processed tx: {}'.format(tx.index))\n",
    "       \n",
    "    nodes=list(itertools.chain.from_iterable(nodes))\n",
    "    edges=list(itertools.chain.from_iterable(edges))\n",
    "    \n",
    "    # Input to graph\n",
    "    \n",
    "    graph.add_nodes_from(nodes)\n",
    "    graph.add_edges_from(edges)\n",
    "        \n",
    "\n",
    "    #print('Generated Graph for Block starting at:{}'.format(init_block))\n",
    "    return graph\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'blocks' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-15-5122ed51fba6>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# Test BlockGraph\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mgraph\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mblock_graph\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mblocks\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0;31m#print (len(graph))\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mnx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minfo\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgraph\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'blocks' is not defined"
     ]
    }
   ],
   "source": [
    "# Test BlockGraph\n",
    "\n",
    "graph=block_graph(blocks)\n",
    "#print (len(graph))\n",
    "nx.info(graph)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "def identity(x):\n",
    "    return x\n",
    "\n",
    "\n",
    "def extract_nodes_edges(transaction):\n",
    "    \n",
    "    # Initialize values and get info from transaction\n",
    "    edges=[]\n",
    "    output_value=transaction.output_value\n",
    "    block_height=transaction.block_height\n",
    "    tx_id=transaction.index\n",
    "    \n",
    "    # Get inputs, types and values\n",
    "    inputs=transaction.inputs.address\n",
    "    #input_types=transaction.inputs.address.raw_type\n",
    "    #input_block=transaction.inputs.address.first_tx.block.height\n",
    "    input_val=transaction.inputs.value\n",
    "    \n",
    "    input_nodes=[(inp.address_num,{'raw_type':inp.raw_type,'block_created':inp.first_tx.block.height})for inp in inputs]\n",
    "    \n",
    "\n",
    "    # Get outputs and types\n",
    "    outputs=transaction.outputs.address\n",
    "    #output_types=transaction.outputs.address.raw_type\n",
    "    #output_block=transaction.outputs.address.first_tx.block.height\n",
    "    output_nodes=[(out.address_num,{'raw_type':out.raw_type,'block_created':out.first_tx.block.height})for out in outputs]\n",
    "  \n",
    "    # ****TODO: Add address balance as attribute to node**** \n",
    "    \n",
    "    # Create nodes \n",
    "    \n",
    "    nodes=input_nodes+output_nodes\n",
    "    \n",
    "    # Create edges (NetworkX will automatically create nodes when given edges)\n",
    "  \n",
    "    for i in range(len(inputs)):\n",
    "        value=input_val[i]\n",
    "        prop_value=value/len(outputs)\n",
    "        \n",
    "        for o in range(len(outputs)): \n",
    "            edge=(inputs[i].address_num,outputs[o].address_num,{'value':prop_value,'tx_id':block_height})\n",
    "            edges.append(edge)\n",
    "    \n",
    "    return edges,nodes\n",
    "            \n",
    "            \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "704f384862b91ff5d2cd170df55826f94c0d93f014d4ccf82406fabd61582434\n",
      "[(19464725, {'block_created': 264954, 'raw_type': 2}), (40165049, {'block_created': 309015, 'raw_type': 2}), (30517405, {'block_created': 290181, 'raw_type': 2})]\n",
      "[(19464725, 40165049, {'tx_id': 309015, 'value': 2500000.0}), (19464725, 30517405, {'tx_id': 309015, 'value': 2500000.0})]\n"
     ]
    }
   ],
   "source": [
    "# Test extract nodes_edges\n",
    "\n",
    "test_tx=chain.tx_with_index(41847232)\n",
    "edges,nodes=extract_nodes_edges(test_tx)\n",
    "print(test_tx.hash)\n",
    "print(nodes)\n",
    "print(edges)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
