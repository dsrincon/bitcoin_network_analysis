{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Bitcoin Transaction Network Analysis - Data Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of CPUs: 8\n"
     ]
    }
   ],
   "source": [
    "import blocksci\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import networkx as nx\n",
    "import matplotlib.pyplot as plt\n",
    "import multiprocessing as mp\n",
    "import itertools\n",
    "import random\n",
    "import time\n",
    "import string\n",
    "import pickle\n",
    "import csv\n",
    "import gc\n",
    "import os, sys\n",
    "from functools import partial\n",
    "%matplotlib notebook\n",
    "ncpu=mp.cpu_count()\n",
    "print('Number of CPUs: {}'.format(ncpu))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "15"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total Blocks up to 2019-04-17 16:57:37:  572046 \n"
     ]
    }
   ],
   "source": [
    "# Point to parsed blockchain data\n",
    "chain = blocksci.Blockchain(\"/home/ubuntu/bitcoin\")\n",
    "types=blocksci.address_type.types\n",
    "total_blocks=chain.blocks\n",
    "print('Total Blocks up to {}:  {} '.format(total_blocks[-1].time,len(total_blocks)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Network Definition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extraction id: 1lTbD3\n",
      "Start_block: 37494\n",
      "End_block: 507089\n",
      "Number of Blocks: 469596 \n",
      "Highest block height: 507089\n",
      "Number of Transactions: 500 \n",
      "Number of parts: 500\n",
      "115712 Processed\n",
      "143362 Processed\n",
      "488453 Processed\n",
      "167425 Processed\n",
      "458760 Processed\n",
      "342025 Processed\n",
      "242706 Processed\n",
      "327699 Processed\n",
      "161813 Processed\n",
      "473110 Processed\n",
      "379927 Processed\n",
      "176152 Processed\n",
      "111962 Processed\n",
      "299041 Processed\n",
      "341026 Processed\n",
      "442406 Processed\n",
      "105511 Processed\n",
      "403617 Processed\n",
      "338987 Processed\n",
      "218156 Processed\n",
      "78893 Processed\n",
      "492381 Processed\n",
      "72752 Processed\n",
      "114696 Processed\n",
      "115765 Processed\n",
      "173113 Processed\n",
      "190899 Processed\n",
      "320573 Processed\n",
      "153662 Processed\n",
      "405173 Processed\n",
      "394305 Processed\n",
      "162785 Processed\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-52-b4b8d956832f>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     35\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     36\u001b[0m \u001b[0mpartition\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mBchainPartition\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mchain\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mstart\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mend\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0msample_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msample_size\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 37\u001b[0;31m \u001b[0mdf\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mgraphs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mpartition_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpartition\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mdirectory\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mfilename\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     38\u001b[0m \u001b[0mdf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhead\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     39\u001b[0m \u001b[0mend_time\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-50-b66157d139c6>\u001b[0m in \u001b[0;36mpartition_data\u001b[0;34m(chainpartiton, directory, filename)\u001b[0m\n\u001b[1;32m     17\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mt\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtuples\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 19\u001b[0;31m         \u001b[0mdata_i\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mcolumns_i\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mgraph_i\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mgraph_features\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mt\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mslice_type\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'blocks'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     20\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     21\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilename\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'a'\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-8-aa7affe839cb>\u001b[0m in \u001b[0;36mgraph_features\u001b[0;34m(chain_part_tuple, slice_type)\u001b[0m\n\u001b[1;32m      6\u001b[0m     \u001b[0mchain_part\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mchain_part_tuple\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m     \u001b[0mblock_height\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mchain_part\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mblock_height\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m     \u001b[0mgraph\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mblock_graph\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mchain_part\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mslice_type\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      9\u001b[0m     \u001b[0mnx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minfo\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgraph\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m     \u001b[0mnodes\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mgraph\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnodes\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-9-b27613035fc9>\u001b[0m in \u001b[0;36mblock_graph\u001b[0;34m(txs, index, slice_type)\u001b[0m\n\u001b[1;32m     37\u001b[0m     '''\n\u001b[1;32m     38\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mtx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtxs\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 39\u001b[0;31m         \u001b[0medges_i\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mnodes_i\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mextract_nodes_edges\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     40\u001b[0m         \u001b[0mnodes\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnodes_i\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     41\u001b[0m         \u001b[0medges\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0medges_i\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-10-d1b94e85a4ae>\u001b[0m in \u001b[0;36mextract_nodes_edges\u001b[0;34m(transaction)\u001b[0m\n\u001b[1;32m     15\u001b[0m     \u001b[0minput_val\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtransaction\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 17\u001b[0;31m     \u001b[0minput_nodes\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0maddress_num\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0;34m'raw_type'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0minp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mraw_type\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'block_created'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0minp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfirst_tx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mblock\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mheight\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;32mfor\u001b[0m \u001b[0minp\u001b[0m \u001b[0;32min\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     18\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-10-d1b94e85a4ae>\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m     15\u001b[0m     \u001b[0minput_val\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtransaction\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 17\u001b[0;31m     \u001b[0minput_nodes\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0maddress_num\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0;34m'raw_type'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0minp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mraw_type\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'block_created'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0minp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfirst_tx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mblock\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mheight\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;32mfor\u001b[0m \u001b[0minp\u001b[0m \u001b[0;32min\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     18\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "#---SCRIPT: generates data for graphs in each part of the partition\n",
    "\n",
    "# Create directories and files to store graphs and dataframe\n",
    "\n",
    "# Generate an extraction ID (Each id has random id)\n",
    "extraction_id = ''.join([random.choice(string.ascii_letters + string.digits) for n in range(6)])\n",
    "print('Extraction id: {}'.format(extraction_id))\n",
    "\n",
    "#---Save Dataframes\n",
    "\n",
    "# Create directory and save\n",
    "\n",
    "start='2010-02-01 00:00:00'\n",
    "end='2018-02-01 11:59:59'\n",
    "blocks=chain.range(start=start,end=end)\n",
    "sample_size=500\n",
    "\n",
    "start_c=start\n",
    "start_c=start_c.replace('-','_').replace(' ','_').replace(':','_')\n",
    "end_c=end\n",
    "end_c=end_c.replace('-','_').replace(' ','_').replace(':','_')\n",
    "\n",
    "directory='extractions/'+extraction_id+'-'+str(sample_size)+'-blocks-'+start_c+'-'+end_c+'/graphs'+'/'\n",
    "\n",
    "\n",
    "if not os.path.exists(directory):\n",
    "    os.makedirs(directory)\n",
    "\n",
    "# Create Filename and save\n",
    "\n",
    "filename='extractions/'+extraction_id+'-'+str(sample_size)+'-blocks-'+start_c+'-'+end_c+'/'+extraction_id+'-'+str(sample_size)+'-blocks-'+start_c+'-'+end_c+'.csv'\n",
    "\n",
    "\n",
    "start_time=time.time()\n",
    "\n",
    "partition=BchainPartition(chain,start,end,sample_size=sample_size)\n",
    "df,graphs=partition_data(partition,directory,filename)\n",
    "df.head()\n",
    "end_time=time.time()\n",
    "print('Time taken={}'.format(end_time-start_time))\n",
    "print('\\n***EXTRACTION COMPLETED SUCCESSFULLY***')\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Class that creates a blockchain a blockchain partition (dictionary) given data range and partition type (blocks,days,weeks)\n",
    "\n",
    "class BchainPartition():\n",
    "    \n",
    "    def __init__(self,chain,start_timestamp,end_timestamp,ptype='blocks',sample_size=10):\n",
    "        blocks=chain.range(start=start_timestamp,end=end_timestamp)\n",
    "        \n",
    "        \n",
    "        self.block_h=blocks.height\n",
    "        print('Start_block: {}'.format(self.block_h[0]))\n",
    "        print('End_block: {}'.format(self.block_h[-1]))\n",
    "        \n",
    "        if sample_size>0: #Samples blocks from the \n",
    "            sample_list=list(np.random.choice(self.block_h,sample_size))\n",
    "            sample_blocks=[chain[ix_b] for ix_b in sample_list]\n",
    "            txs=[b.txes for b in sample_blocks]\n",
    "            self.partition={h:[t for t in t_l] for h,t_l in zip(sample_list,txs)}\n",
    "            self.no_parts=len(sample_blocks)\n",
    "            \n",
    "        else:  \n",
    "            if ptype=='blocks':\n",
    "                self.partition={b.height:[tx for tx in b.txes] for b in blocks}\n",
    "                self.no_parts=np.int32(len(blocks))\n",
    "                \n",
    "        \n",
    "        print('Number of Blocks: {} '.format(len(blocks)))\n",
    "        print('Highest block height: {}'.format(blocks[-1].height))\n",
    "        print('Number of Transactions: {} '.format(len(txs)))\n",
    "\n",
    "        # ***TODO: Create partition for other types of partitions (use tx.block_time)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function that takes blockchain partition and outputs pandas data frame with features \n",
    "# for the graph defined by each split in the partition\n",
    "\n",
    "def partition_data(chainpartiton,directory,filename):\n",
    "    \n",
    "    # Dictionary with partition\n",
    "    partition=chainpartiton.partition\n",
    "    partindex=partition.keys()\n",
    "    parts=partition.values()\n",
    "    data_tuples=[]\n",
    "    graphs=[]\n",
    "    \n",
    "    print('Number of parts: {}'.format(len(partindex)))\n",
    "    \n",
    "    tuples=[(index,part) for index,part in zip(partindex,parts)]\n",
    "    \n",
    "    for t in tuples:\n",
    "        \n",
    "        data_i,columns_i,graph_i=graph_features(t,slice_type='blocks')\n",
    "        \n",
    "        with open(filename,'a') as f:\n",
    "            writer = csv.writer(f, delimiter=',')\n",
    "            if len(data_tuples)==0: # Write column names on first pass\n",
    "                writer.writerow(columns_i)\n",
    "            writer.writerow(data_i)\n",
    "        # Save graph\n",
    "        nx.write_gpickle(graph_i,directory+str(graph_i.graph['graph_id'])+'.gpickle') \n",
    "        \n",
    "        data_tuples.append((data_i,columns_i))\n",
    "        graphs.append(graph_i)\n",
    "         \n",
    "    \n",
    "    '''    \n",
    "    chunksize=len(tuples)%ncpu\n",
    "    with mp.Pool(processes=ncpu) as pool:\n",
    "        data_tuples=pool.map(graph_features,tuples,chunksize)\n",
    "    \n",
    "    '''\n",
    "    \n",
    "    columns=data_tuples[0][1] #This value is being re-written. This design choice is to mantain consistency with columns.\n",
    "    data=[i for i,j in data_tuples]\n",
    "    data=np.array(data)    \n",
    "    df=pd.DataFrame(data=data[:,:],columns=columns)\n",
    "    \n",
    "    \n",
    "    return (df,graphs)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function that receives a chain part (list of transactions), generates transaction graph and calculates statistics\n",
    "\n",
    "def graph_features(chain_part_tuple,slice_type='blocks'):\n",
    "    \n",
    "    index=chain_part_tuple[0]\n",
    "    chain_part=chain_part_tuple[1]\n",
    "    block_height=chain_part[-1].block_height\n",
    "    graph=block_graph(chain_part,index,slice_type)\n",
    "    nx.info(graph)\n",
    "    nodes=graph.nodes(data=True)\n",
    "    edges=graph.edges(data=True)\n",
    "    data=[index]  \n",
    "    columns=['block_height']\n",
    "    \n",
    "    # Number of Nodes\n",
    "    no_nodes=nx.number_of_nodes(graph)\n",
    "    data.append(no_nodes)\n",
    "    columns.append('no_nodes')\n",
    "    \n",
    "    # Number of Edges (address to address transactions)\n",
    "    no_edges=nx.number_of_edges(graph)\n",
    "    data.append(no_edges)\n",
    "    columns.append('no_edges')\n",
    "    \n",
    "    # Total value transacted\n",
    "    total_value=np.sum(np.array([a['value'] for n1,n2,a in edges]))\n",
    "    data.append(total_value)\n",
    "    columns.append('value_transacted')\n",
    "    \n",
    "    # Total Density\n",
    "    density=nx.density(graph)\n",
    "    data.append(density)\n",
    "    columns.append('total_density')\n",
    "    \n",
    "    # Nodes with self loops nx.loops nodes_with_selfloops(G) nodes_with_selfloops(G) \n",
    "    nodes_self=nx.number_of_selfloops(graph)\n",
    "    data.append(nodes_self)\n",
    "    columns.append('nodes_self')\n",
    "    \n",
    "    # Value of self loops nodes_with_selfloops(G)\n",
    "    values=np.array([a['value'] for n1,n2,a in nx.selfloop_edges(graph,data=True)])\n",
    "    selfloop_value=np.sum(values)\n",
    "    data.append(selfloop_value)\n",
    "    columns.append('selfloop_value')\n",
    "    \n",
    "    # Number of transactions to old addresses \n",
    "    \n",
    "    old_nodes=[n for n,a in nodes if a['block_created']<block_height]\n",
    "    edges_to_old=graph.in_edges(old_nodes,data=True)\n",
    "    data.append(len(edges_to_old))\n",
    "    columns.append('old_nodes_in')\n",
    "    \n",
    "    # Ratio of transactions to old addresses to total transactions\n",
    "    \n",
    "    ratio_oldin_totalin=len(edges_to_old)/(no_edges+1)\n",
    "    data.append(ratio_oldin_totalin)\n",
    "    columns.append('ratio_oldin_totalin')\n",
    "    \n",
    "    # Value of transactions to old addresses\n",
    "    \n",
    "    value_to_old=[a['value'] for n1,n2,a in edges_to_old]\n",
    "    data.append(np.sum(np.array(value_to_old)))\n",
    "    columns.append('value_to_old')\n",
    "    \n",
    "    # Old address density\n",
    "    \n",
    "    old_graph=nx.induced_subgraph(graph,old_nodes)\n",
    "    old_density=nx.density(old_graph)\n",
    "    data.append(old_density)\n",
    "    columns.append('old_density')\n",
    "    \n",
    "    \n",
    "    # ***TODO*** (Aggregated graph analysis)\n",
    "    \n",
    "    # Accumulated reuse\n",
    "    # Dominance (Agg graph or new vs. old dominance) \n",
    "    #https://networkx.github.io/documentation/stable/reference/algorithms/dominance.html\n",
    "    # Common ancenstors (as with dominance the address ancestor path should be proportional \n",
    "    #to the blockchain lenght if address reuse is minimal)\n",
    "    #***********\n",
    "    \n",
    "    print('{} Processed'.format(index))\n",
    "    return (data,columns,graph)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function that creates transaction graph for a given number transactions\n",
    "\n",
    "\n",
    "def block_graph(txs,index,slice_type):\n",
    "\n",
    "    \n",
    "    # Create graph and process \n",
    "    graph = nx.MultiDiGraph(graph_id=index,slice_type=slice_type)\n",
    "    nodes=[]\n",
    "    edges=[]\n",
    "    \n",
    "    \n",
    "    # Extract transactions information\n",
    "    \n",
    "    init_block=txs[0].block.height\n",
    "    txs_dic={tx.index:tx for tx in txs}\n",
    "    txs_ix=list(txs_dic.keys())\n",
    "    txs_ix.sort()\n",
    "   \n",
    "    \n",
    "    start_ix=txs_ix[0]\n",
    "    end_ix=txs_ix[-1]\n",
    "    \n",
    "    \n",
    "    # Generate edges to input to graph\n",
    "    \n",
    "    chunksize=len(txs)%ncpu\n",
    "   \n",
    "    #edges=chain.mapreduce_txes(extract_nodes_edges, lambda x: x , init=None, start=start_ix, end=end_ix, cpu_count=8)\n",
    "    #edges=chain.mapreduce_txes(identity, identity, init=missing_param, start=start_ix, end=end_ix, cpu_count=8)\n",
    "\n",
    "    '''\n",
    "    with mp.Pool(processes=ncpu) as pool:\n",
    "        edges=pool.map(extract_nodes_edges,txs,chunksize)\n",
    "        \n",
    "   \n",
    "    '''\n",
    "    for tx in txs:\n",
    "        edges_i,nodes_i=extract_nodes_edges(tx)\n",
    "        nodes.append(nodes_i)\n",
    "        edges.append(edges_i)\n",
    "        #print('Processed tx: {}'.format(tx.index))\n",
    "       \n",
    "    nodes=list(itertools.chain.from_iterable(nodes))\n",
    "    edges=list(itertools.chain.from_iterable(edges))\n",
    "    \n",
    "    # Input to graph\n",
    "    \n",
    "    graph.add_nodes_from(nodes)\n",
    "    graph.add_edges_from(edges)\n",
    "        \n",
    "\n",
    "    #print('Generated Graph for Block starting at:{}'.format(init_block))\n",
    "    return graph\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function that receives a transaction and generates nodes and edges from addresses in transaction\n",
    "\n",
    "def extract_nodes_edges(transaction):\n",
    "    \n",
    "    # Initialize values and get info from transaction\n",
    "    edges=[]\n",
    "    output_value=transaction.output_value\n",
    "    block_height=transaction.block_height\n",
    "    tx_id=transaction.index\n",
    "    \n",
    "    # Get inputs, types and values\n",
    "    inputs=transaction.inputs.address\n",
    "    #input_types=transaction.inputs.address.raw_type\n",
    "    #input_block=transaction.inputs.address.first_tx.block.height\n",
    "    input_val=transaction.inputs.value\n",
    "    \n",
    "    input_nodes=[(inp.address_num,{'raw_type':inp.raw_type,'block_created':inp.first_tx.block.height})for inp in inputs]\n",
    "    \n",
    "\n",
    "    # Get outputs and types\n",
    "    outputs=transaction.outputs.address\n",
    "    #output_types=transaction.outputs.address.raw_type\n",
    "    #output_block=transaction.outputs.address.first_tx.block.height\n",
    "    output_nodes=[(out.address_num,{'raw_type':out.raw_type,'block_created':out.first_tx.block.height})for out in outputs]\n",
    "  \n",
    "    # ****TODO: Add address balance as attribute to node**** \n",
    "    \n",
    "    # Create nodes \n",
    "    \n",
    "    nodes=input_nodes+output_nodes\n",
    "    \n",
    "    # Create edges (NetworkX will automatically create nodes when given edges)\n",
    "  \n",
    "    # TODO: Correct value definition\n",
    "    for i in range(len(inputs)):\n",
    "        value=input_val[i]\n",
    "        prop_value=value/len(outputs)\n",
    "        \n",
    "        for o in range(len(outputs)): \n",
    "            edge=(inputs[i].address_num,outputs[o].address_num,{'value':prop_value,'tx_id':block_height})\n",
    "            edges.append(edge)\n",
    "    \n",
    "    return edges,nodes\n",
    "            \n",
    "            \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "704f384862b91ff5d2cd170df55826f94c0d93f014d4ccf82406fabd61582434\n",
      "[(19464725, {'block_created': 264954, 'raw_type': 2}), (40165049, {'block_created': 309015, 'raw_type': 2}), (30517405, {'block_created': 290181, 'raw_type': 2})]\n",
      "[(19464725, 40165049, {'value': 2500000.0, 'tx_id': 309015}), (19464725, 30517405, {'value': 2500000.0, 'tx_id': 309015})]\n"
     ]
    }
   ],
   "source": [
    "# Test extract nodes_edges\n",
    "\n",
    "test_tx=chain.tx_with_index(41847232)\n",
    "edges,nodes=extract_nodes_edges(test_tx)\n",
    "print(test_tx.hash)\n",
    "print(nodes)\n",
    "print(edges)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
